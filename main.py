#!/usr/bin/env python3
"""
PDF to Question Converter - ä¸»ç¨‹åºå…¥å£
å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„é¢˜ç›®æ•°æ®ï¼Œé€‚ç”¨äºè€ƒè¯•é¢˜åº“å»ºè®¾

ä½¿ç”¨æµç¨‹:
1. PDF -> JSON (ä½¿ç”¨magic-pdfå·¥å…·)  æˆ–  ç›´æ¥ä½¿ç”¨JSONæ–‡ä»¶
2. JSON -> æ ‡å‡†åŒ–é¢˜ç›®æ•°æ® (ä½¿ç”¨SiliconFlow AI)

æ”¯æŒæ‰¹é‡å¤„ç†å’Œå•æ–‡ä»¶å¤„ç†æ¨¡å¼
æ”¯æŒPDFæ–‡ä»¶å’ŒJSONæ–‡ä»¶ä½œä¸ºè¾“å…¥
"""

import os
import sys
import json
import argparse
import asyncio
import shutil
import tempfile
from pathlib import Path
from typing import List, Dict, Optional
import re

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from convertPdf2Json import ConvertPdf2Json
from aiJson2Questions import transform_raw_text_to_mongo_questions
from splitJson import split_json_with_folder, merge_json_files
from config import config

class PDF2QuestionConverter:
    """PDFåˆ°é¢˜ç›®è½¬æ¢å™¨ä¸»ç±»"""
    
    def __init__(self, siliconflow_api_key: Optional[str] = None):
        self.api_key = siliconflow_api_key or os.getenv("SILICONFLOW_API_KEY")
        if not self.api_key or self.api_key == "YOUR_SILICONFLOW_API_KEY_HERE":
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY æˆ–é€šè¿‡å‚æ•°ä¼ å…¥APIå¯†é’¥")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä¾›å­æ¨¡å—ä½¿ç”¨
        os.environ["SILICONFLOW_API_KEY"] = self.api_key
    
    def detect_input_type(self, input_path: str) -> str:
        """æ£€æµ‹è¾“å…¥æ–‡ä»¶ç±»å‹"""
        if os.path.isfile(input_path):
            if input_path.lower().endswith('.pdf'):
                return "pdf_file"
            elif input_path.lower().endswith('.json'):
                return "json_file"
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {input_path}")
        elif os.path.isdir(input_path):
            # æ£€æŸ¥ç›®å½•ä¸­çš„æ–‡ä»¶ç±»å‹
            pdf_files = []
            json_files = []
            for root, dirs, files in os.walk(input_path):
                for file in files:
                    if file.lower().endswith('.pdf'):
                        pdf_files.append(file)
                    elif file.lower().endswith('.json'):
                        json_files.append(file)
            
            if pdf_files and json_files:
                raise ValueError(f"ç›®å½•ä¸­åŒæ—¶åŒ…å«PDFå’ŒJSONæ–‡ä»¶ï¼Œè¯·åˆ†åˆ«å¤„ç†: {input_path}")
            elif pdf_files:
                return "pdf_folder"
            elif json_files:
                return "json_folder"
            else:
                raise ValueError(f"ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°PDFæˆ–JSONæ–‡ä»¶: {input_path}")
        else:
            raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    def validate_paths(self, input_path: str, output_dir: str) -> None:
        """éªŒè¯è¾“å…¥è¾“å‡ºè·¯å¾„"""
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    def convert_single_pdf_to_json(self, pdf_file: str, json_output_dir: str, mode: str = "auto") -> List[str]:
        """å•ä¸ªPDFæ–‡ä»¶è½¬JSON"""
        print(f"\n=== ç¬¬ä¸€æ­¥ï¼šPDFè½¬JSON ===")
        print(f"è¾“å…¥æ–‡ä»¶: {pdf_file}")
        print(f"è¾“å‡ºç›®å½•: {json_output_dir}")
        print(f"æ¨¡å¼: {mode}")
        
        # ä¸ºå•ä¸ªæ–‡ä»¶åˆ›å»ºä¸´æ—¶ç›®å½•ç»“æ„
        temp_pdf_dir = os.path.join(json_output_dir, "temp_pdf_input")
        os.makedirs(temp_pdf_dir, exist_ok=True)
        
        # å¤åˆ¶PDFæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        temp_pdf_path = os.path.join(temp_pdf_dir, os.path.basename(pdf_file))
        shutil.copy2(pdf_file, temp_pdf_path)
        
        try:
            # ä½¿ç”¨ä¸´æ—¶ç›®å½•ä½œä¸ºè¾“å…¥
            converter = ConvertPdf2Json(temp_pdf_dir, json_output_dir, mode)
            success = converter.convert()
            
            if not success:
                raise RuntimeError("PDFè½¬æ¢å¤±è´¥")
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„JSONæ–‡ä»¶
            json_files = []
            for root, dirs, files in os.walk(json_output_dir):
                for file in files:
                    if file.endswith('.json') and not root.endswith('temp_pdf_input'):
                        json_files.append(os.path.join(root, file))
            
            print(f"ç”Ÿæˆçš„JSONæ–‡ä»¶: {len(json_files)} ä¸ª")
            return json_files
            
        finally:
            # æ¸…ç†ä¸´æ—¶PDFç›®å½•
            if os.path.exists(temp_pdf_dir):
                shutil.rmtree(temp_pdf_dir, ignore_errors=True)
    
    def convert_pdf_folder_to_json(self, pdf_folder: str, json_output_dir: str, mode: str = "auto") -> List[str]:
        """PDFæ–‡ä»¶å¤¹è½¬JSON"""
        print(f"\n=== ç¬¬ä¸€æ­¥ï¼šPDFè½¬JSON ===")
        print(f"è¾“å…¥æ–‡ä»¶å¤¹: {pdf_folder}")
        print(f"è¾“å‡ºç›®å½•: {json_output_dir}")
        print(f"æ¨¡å¼: {mode}")
        
        converter = ConvertPdf2Json(pdf_folder, json_output_dir, mode)
        success = converter.convert()
        
        if not success:
            raise RuntimeError("PDFè½¬æ¢å¤±è´¥")
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„JSONæ–‡ä»¶
        json_files = []
        for root, dirs, files in os.walk(json_output_dir):
            for file in files:
                if file.endswith('.json'):
                    json_files.append(os.path.join(root, file))
        
        print(f"ç”Ÿæˆçš„JSONæ–‡ä»¶: {len(json_files)} ä¸ª")
        return json_files
    
    def collect_json_files(self, input_path: str) -> List[str]:
        """æ”¶é›†JSONæ–‡ä»¶ï¼ˆç›´æ¥è¾“å…¥JSONæ—¶ä½¿ç”¨ï¼‰"""
        print(f"\n=== æ£€æµ‹åˆ°JSONè¾“å…¥ï¼Œè·³è¿‡PDFè½¬æ¢æ­¥éª¤ ===")
        
        json_files = []
        if os.path.isfile(input_path):
            json_files = [input_path]
            print(f"å•ä¸ªJSONæ–‡ä»¶: {input_path}")
        elif os.path.isdir(input_path):
            for root, dirs, files in os.walk(input_path):
                for file in files:
                    if file.lower().endswith('.json'):
                        json_files.append(os.path.join(root, file))
            print(f"JSONæ–‡ä»¶å¤¹: {input_path}")
            print(f"å‘ç° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
        
        if not json_files:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„JSONæ–‡ä»¶")
        
        return json_files
    
    async def convert_json_to_questions(self, json_files: List[str], output_file: str) -> List[Dict]:
        """ç¬¬äºŒæ­¥ï¼šJSONè½¬é¢˜ç›®æ•°æ®ï¼ˆæ”¯æŒè‡ªåŠ¨åˆ‡åˆ†å’Œæ‹¼åˆï¼‰"""
        print(f"\n=== ç¬¬äºŒæ­¥ï¼šJSONè½¬é¢˜ç›®æ•°æ® ===")
        print(f"å¤„ç† {len(json_files)} ä¸ªJSONæ–‡ä»¶")
        
        all_questions = []
        
        # åˆ›å»ºåˆ‡ç‰‡å’Œè¾“å‡ºç›®å½•
        base_output_dir = os.path.dirname(output_file)
        chunks_base_dir = os.path.join(base_output_dir, "åˆ‡ç‰‡")
        results_base_dir = os.path.join(base_output_dir, "results")
        os.makedirs(chunks_base_dir, exist_ok=True)
        os.makedirs(results_base_dir, exist_ok=True)
        
        for i, json_file in enumerate(json_files, 1):
            print(f"\nå¤„ç†æ–‡ä»¶ {i}/{len(json_files)}: {os.path.basename(json_file)}")
            
            try:
                # è§£æJSONæ–‡ä»¶
                json_data = await self._parse_json_file(json_file)
                if not json_data:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡åˆ†
                file_questions = await self._process_json_with_chunking(
                    json_file, json_data, chunks_base_dir, results_base_dir
                )
                
                if file_questions:
                    all_questions.extend(file_questions)
                    print(f"âœ… æ–‡ä»¶ {os.path.basename(json_file)} å¤„ç†å®Œæˆ: {len(file_questions)} é“é¢˜ç›®")
                else:
                    print(f"âŒ æ–‡ä»¶ {os.path.basename(json_file)} å¤„ç†å¤±è´¥: æ— é¢˜ç›®è¾“å‡º")
                    
            except Exception as e:
                print(f"é”™è¯¯: å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                import traceback
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
                continue
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        print(f"\næ€»è®¡è½¬æ¢é¢˜ç›®: {len(all_questions)} é“")
        
        # å¯¹é¢˜ç›®æ•°æ®è¿›è¡Œè¿‡æ»¤å’Œå¤„ç†
        print(f"ğŸ“‹ å¼€å§‹è¿‡æ»¤å’Œå¤„ç†é¢˜ç›®æ•°æ®...")
        filtered_questions = []
        removed_count = 0
        processed_count = 0
        
        for question in all_questions:
            # a. å¦‚æœtypeä¸å±äºsingleã€multipleï¼Œé‚£ä¹ˆç›´æ¥åˆ é™¤è¿™ä¸ªæ¡ç›®
            question_type = question.get("type", "")
            if question_type not in ["single", "multiple"]:
                removed_count += 1
                print(f"  âŒ åˆ é™¤é¢˜ç›® (ç±»å‹: {question_type}): {question.get('content', 'æœªçŸ¥é¢˜ç›®')[:50]}...")
                continue
            
            # b. å¦‚æœç¼ºä¹explanationå­—æ®µï¼Œé‚£ä¹ˆæ·»åŠ ä¸Šè¿™ä¸ªå­—æ®µï¼Œé»˜è®¤ä¸ºç©º
            if "explanation" not in question or question["explanation"] is None:
                question["explanation"] = ""
                processed_count += 1
            
            filtered_questions.append(question)
        
        print(f"  âœ… è¿‡æ»¤å®Œæˆ: ä¿ç•™ {len(filtered_questions)} é“é¢˜ç›®ï¼Œåˆ é™¤ {removed_count} é“é¢˜ç›®")
        print(f"  ğŸ”§ å¤„ç†å®Œæˆ: è¡¥å…… {processed_count} ä¸ªexplanationå­—æ®µ")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(filtered_questions, f, ensure_ascii=False, indent=2)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        print(f"æœ€ç»ˆè¾“å‡º: {len(filtered_questions)} é“æœ‰æ•ˆé¢˜ç›®")
        return filtered_questions
    
    async def _parse_json_file(self, json_file: str) -> List[Dict]:
        """è§£æJSONæ–‡ä»¶ï¼Œå¤„ç†å„ç§æ ¼å¼é—®é¢˜"""
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            # å°è¯•ä¿®å¤JSONæ ¼å¼é—®é¢˜
            try:
                json_data = json.loads(content)
            except json.JSONDecodeError as e:
                print(f"åŸå§‹JSONè§£æå¤±è´¥: {e}")
                print("å°è¯•ä¿®å¤JSONæ ¼å¼...")
                
                # å°è¯•ä¿®å¤JavaScriptå¯¹è±¡æ ¼å¼ï¼ˆæ²¡æœ‰å¼•å·çš„é”®åï¼‰
                try:
                    # ä¿®å¤ { type: "text" } æ ¼å¼ä¸º { "type": "text" }
                    fixed_content = re.sub(r'(\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', content)
                    # ä¿®å¤çœç•¥å·
                    fixed_content = re.sub(r'â€¦\s*}', '}', fixed_content)
                    
                    # å¦‚æœæ˜¯å•è¡Œæ ¼å¼ï¼Œå°è¯•è§£æä¸ºæ•°ç»„
                    if '\n' in fixed_content and not fixed_content.strip().startswith('['):
                        # æŒ‰è¡Œåˆ†å‰²å¹¶æ„å»ºæ•°ç»„
                        lines = []
                        for line in fixed_content.strip().split('\n'):
                            line = line.strip()
                            if line and not line.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')):
                                # è·³è¿‡è¡Œå·
                                try:
                                    # å°è¯•è§£æå•è¡Œå¯¹è±¡
                                    obj = json.loads(line)
                                    lines.append(obj)
                                except:
                                    continue
                            elif line.startswith('{'):
                                try:
                                    obj = json.loads(line)
                                    lines.append(obj)
                                except:
                                    continue
                        
                        if lines:
                            json_data = lines
                        else:
                            print(f"æ— æ³•ä¿®å¤JSONæ ¼å¼ï¼Œå°è¯•é€è¡Œè§£æ...")
                            json_data = self._parse_lines_manually(content)
                    else:
                        json_data = json.loads(fixed_content)
                        
                except Exception as e2:
                    print(f"JSONæ ¼å¼ä¿®å¤å¤±è´¥: {e2}")
                    print("å°è¯•é€è¡Œè§£æ...")
                    json_data = self._parse_lines_manually(content)
            
            # æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
            if isinstance(json_data, list):
                formatted_data = []
                for item in json_data:
                    if isinstance(item, dict) and 'text' in item:
                        formatted_data.append(item)
                    elif isinstance(item, str):
                        formatted_data.append({"text": item, "type": "text"})
                return formatted_data
            else:
                return [{"text": str(json_data), "type": "text"}]
                
        except Exception as e:
            print(f"è§£æJSONæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    async def _process_json_with_chunking(self, json_file: str, json_data: List[Dict], 
                                        chunks_base_dir: str, results_base_dir: str) -> List[Dict]:
        """å¤„ç†JSONæ–‡ä»¶ï¼Œå¦‚æœéœ€è¦åˆ™è¿›è¡Œåˆ‡åˆ†å’Œæ‹¼åˆ"""
        # ä¼°ç®—æ–‡æœ¬æ€»é•¿åº¦
        total_text_length = 0
        valid_text_lines = 0
        
        for item in json_data:
            if isinstance(item, dict) and 'text' in item:
                text = item['text']
                if text and text.strip():
                    total_text_length += len(text)
                    valid_text_lines += 1
        
        print(f"  æœ‰æ•ˆæ–‡æœ¬è¡Œæ•°: {valid_text_lines}")
        print(f"  æ–‡æœ¬æ€»é•¿åº¦: {total_text_length} å­—ç¬¦")
        
        # å†³å®šæ˜¯å¦éœ€è¦åˆ‡åˆ†
        if valid_text_lines > 50 or total_text_length > 15000:  # éœ€è¦åˆ‡åˆ†
            print(f"ğŸ“„ æ–‡ä»¶è¾ƒå¤§ï¼Œå¯ç”¨åˆ‡åˆ†å¤„ç†æ¨¡å¼")
            return await self._process_with_chunking(json_file, json_data, chunks_base_dir, results_base_dir)
        else:
            # ç›´æ¥å¤„ç†å°æ–‡ä»¶
            print(f"ğŸ“„ æ–‡ä»¶è¾ƒå°ï¼Œç›´æ¥å¤„ç†")
            try:
                print(f"ğŸ“¡ æ­£åœ¨è°ƒç”¨AIå¤„ç†æ–‡ä»¶...")
                questions = await transform_raw_text_to_mongo_questions(json_data)
                
                if questions:
                    # éªŒè¯è¿”å›æ•°æ®è´¨é‡
                    valid_count = 0
                    for q in questions:
                        if isinstance(q, dict) and q.get("content") and q.get("type"):
                            valid_count += 1
                    
                    print(f"ğŸ“Š AIè¿”å›æ•°æ®: {len(questions)} æ¡è®°å½•ï¼Œ{valid_count} æ¡æœ‰æ•ˆ")
                    print(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {valid_count} é“æœ‰æ•ˆé¢˜ç›®")
                    return questions
                else:
                    print(f"âš ï¸  æ–‡ä»¶å¤„ç†å®Œæˆä½†AIæœªè¿”å›æœ‰æ•ˆé¢˜ç›®æ•°æ®")
                    print(f"ğŸ’¡ å¯èƒ½åŸå› : 1) ç½‘ç»œè¿æ¥é—®é¢˜ 2) AIè¿”å›æ•°æ®æ ¼å¼ä¸è§„èŒƒ 3) æ–‡æœ¬å†…å®¹æ— æ³•è¯†åˆ«ä¸ºé¢˜ç›®")
                    return []
                    
            except Exception as api_error:
                error_type = type(api_error).__name__
                print(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {error_type}")
                
                # åŒºåˆ†é”™è¯¯ç±»å‹å¹¶ç»™å‡ºä¸åŒæç¤º
                if any(net_err in error_type for net_err in ["ReadError", "ConnectError", "TimeoutException"]):
                    print(f"ğŸŒ ç½‘ç»œè¿æ¥é”™è¯¯ - è¿™æ˜¯çœŸæ­£çš„ç½‘ç»œé—®é¢˜")
                    print(f"ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIæœåŠ¡çŠ¶æ€")
                elif "JSON" in str(api_error) or "æ ¼å¼" in str(api_error):
                    print(f"ğŸ“ æ•°æ®æ ¼å¼é”™è¯¯ - AIè¿”å›çš„æ•°æ®ä¸ç¬¦åˆé¢„æœŸæ ¼å¼") 
                    print(f"ğŸ’¡ å»ºè®®: æ£€æŸ¥AIæç¤ºè¯æˆ–æ•°æ®å¤„ç†é€»è¾‘")
                else:
                    print(f"â“ æœªçŸ¥é”™è¯¯ç±»å‹")
                    
                print(f"è¯¦ç»†é”™è¯¯: {str(api_error)[:200]}...")
                raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚å¤„ç†
    
    async def _process_with_chunking(self, json_file: str, json_data: List[Dict], 
                                   chunks_base_dir: str, results_base_dir: str) -> List[Dict]:
        """ä½¿ç”¨åˆ‡åˆ†æ–¹å¼å¤„ç†å¤§æ–‡ä»¶"""
        file_stem = Path(json_file).stem
        
        # ç¬¬ä¸€æ­¥ï¼šåˆ‡åˆ†JSONæ–‡ä»¶
        print(f"  ğŸ”ª æ­£åœ¨åˆ‡åˆ†æ–‡ä»¶...")
        
        # åˆ›å»ºä¸´æ—¶JSONæ–‡ä»¶ç”¨äºåˆ‡åˆ†
        temp_json_file = os.path.join(chunks_base_dir, f"temp_{file_stem}.json")
        with open(temp_json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        try:
            # åˆ‡åˆ†æ–‡ä»¶
            chunk_folder, chunk_files = split_json_with_folder(
                temp_json_file, chunks_base_dir, max_items_per_chunk=50
            )
            
            if not chunk_files:
                print(f"  âŒ åˆ‡åˆ†å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆåˆ‡ç‰‡æ–‡ä»¶")
                return []
            
            # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºç»“æœæ–‡ä»¶å¤¹
            result_folder = os.path.join(results_base_dir, file_stem)
            os.makedirs(result_folder, exist_ok=True)
            
            # ç¬¬ä¸‰æ­¥ï¼šé€ä¸ªå¤„ç†åˆ‡ç‰‡
            print(f"  ğŸ”„ å¤„ç† {len(chunk_files)} ä¸ªåˆ‡ç‰‡...")
            result_files = []
            
            for j, chunk_file in enumerate(chunk_files, 1):
                chunk_name = Path(chunk_file).stem
                result_file = os.path.join(result_folder, f"{chunk_name}_result.json")
                
                print(f"    å¤„ç†åˆ‡ç‰‡ {j}/{len(chunk_files)}: {chunk_name}")
                
                try:
                    # åŠ è½½åˆ‡ç‰‡æ•°æ®
                    with open(chunk_file, 'r', encoding='utf-8') as f:
                        chunk_data = json.load(f)
                    
                    if not chunk_data:
                        print(f"    âš ï¸  åˆ‡ç‰‡ {chunk_name} ä¸ºç©ºï¼Œè·³è¿‡")
                        continue
                    
                    # å¤„ç†åˆ‡ç‰‡
                    try:
                        print(f"    ğŸ“¡ æ­£åœ¨è°ƒç”¨AIå¤„ç†åˆ‡ç‰‡ {chunk_name}...")
                        chunk_questions = await transform_raw_text_to_mongo_questions(chunk_data)
                        
                        if chunk_questions:
                            # éªŒè¯è¿”å›æ•°æ®è´¨é‡
                            valid_count = 0
                            for q in chunk_questions:
                                if isinstance(q, dict) and q.get("content") and q.get("type"):
                                    valid_count += 1
                            
                            print(f"    ğŸ“Š AIè¿”å›æ•°æ®: {len(chunk_questions)} æ¡è®°å½•ï¼Œ{valid_count} æ¡æœ‰æ•ˆ")
                            
                            # ä¿å­˜åˆ‡ç‰‡ç»“æœ
                            with open(result_file, 'w', encoding='utf-8') as f:
                                json.dump(chunk_questions, f, ensure_ascii=False, indent=2)
                            
                            result_files.append(result_file)
                            print(f"    âœ… åˆ‡ç‰‡ {chunk_name} å¤„ç†å®Œæˆ: {valid_count} é“æœ‰æ•ˆé¢˜ç›®")
                        else:
                            print(f"    âš ï¸  åˆ‡ç‰‡ {chunk_name} å¤„ç†å®Œæˆä½†AIæœªè¿”å›æœ‰æ•ˆé¢˜ç›®æ•°æ®")
                            print(f"    ğŸ’¡ å¯èƒ½åŸå› : 1) ç½‘ç»œè¿æ¥é—®é¢˜ 2) AIè¿”å›æ•°æ®æ ¼å¼ä¸è§„èŒƒ 3) æ–‡æœ¬å†…å®¹æ— æ³•è¯†åˆ«ä¸ºé¢˜ç›®")
                            
                    except Exception as api_error:
                        error_type = type(api_error).__name__
                        print(f"    âŒ åˆ‡ç‰‡ {chunk_name} å¤„ç†å¤±è´¥: {error_type}")
                        
                        # åŒºåˆ†é”™è¯¯ç±»å‹å¹¶ç»™å‡ºä¸åŒæç¤º
                        if any(net_err in error_type for net_err in ["ReadError", "ConnectError", "TimeoutException"]):
                            print(f"    ğŸŒ ç½‘ç»œè¿æ¥é”™è¯¯ - è¿™æ˜¯çœŸæ­£çš„ç½‘ç»œé—®é¢˜")
                            print(f"    ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIæœåŠ¡çŠ¶æ€")
                            await asyncio.sleep(config.NETWORK_ERROR_DELAY)  # ç½‘ç»œé”™è¯¯æ—¶é¢å¤–ç­‰å¾…
                        elif "JSON" in str(api_error) or "æ ¼å¼" in str(api_error):
                            print(f"    ğŸ“ æ•°æ®æ ¼å¼é”™è¯¯ - AIè¿”å›çš„æ•°æ®ä¸ç¬¦åˆé¢„æœŸæ ¼å¼")
                            print(f"    ğŸ’¡ å»ºè®®: æ£€æŸ¥AIæç¤ºè¯æˆ–æ•°æ®å¤„ç†é€»è¾‘")
                        else:
                            print(f"    â“ æœªçŸ¥é”™è¯¯ç±»å‹")
                            
                        print(f"    è¯¦ç»†é”™è¯¯: {str(api_error)[:200]}...")
                        # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªåˆ‡ç‰‡
                        continue
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                    if j < len(chunk_files):
                        print(f"    â³ ç­‰å¾…{config.CHUNK_DELAY}ç§’åå¤„ç†ä¸‹ä¸€ä¸ªåˆ‡ç‰‡...")
                        await asyncio.sleep(config.CHUNK_DELAY)
                        
                except Exception as e:
                    print(f"    âŒ å¤„ç†åˆ‡ç‰‡ {chunk_name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {type(e).__name__}")
                    print(f"        é”™è¯¯è¯¦æƒ…: {str(e)[:200]}...")
                    # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
                    continue
            
            # ç¬¬å››æ­¥ï¼šåˆå¹¶ç»“æœ
            if result_files:
                print(f"  ğŸ”— åˆå¹¶ {len(result_files)} ä¸ªç»“æœæ–‡ä»¶...")
                
                merged_questions = []
                for result_file in sorted(result_files):
                    try:
                        with open(result_file, 'r', encoding='utf-8') as f:
                            questions = json.load(f)
                        if isinstance(questions, list):
                            merged_questions.extend(questions)
                    except Exception as e:
                        print(f"    è­¦å‘Š: è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {result_file}, é”™è¯¯: {e}")
                        continue
                
                print(f"  âœ… åˆå¹¶å®Œæˆï¼Œæ€»è®¡ {len(merged_questions)} é“é¢˜ç›®")
                return merged_questions
            else:
                print(f"  âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç»“æœæ–‡ä»¶")
                return []
                
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_json_file):
                os.remove(temp_json_file)
    
    def _parse_lines_manually(self, content: str) -> List[Dict]:
        """æ‰‹åŠ¨é€è¡Œè§£æéæ ‡å‡†JSONæ ¼å¼"""
        lines = []
        for line_num, line in enumerate(content.split('\n'), 1):
            line = line.strip()
            if not line:
                continue
                
            # è·³è¿‡çº¯æ•°å­—è¡Œå·
            if line.isdigit():
                continue
            
            # ç§»é™¤å¼€å¤´çš„è¡Œå·ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # æ ¼å¼å¦‚ "1\t{ type: ..."
            if '\t' in line and line.split('\t')[0].isdigit():
                line = '\t'.join(line.split('\t')[1:])
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯¹è±¡æ ¼å¼
            if line.startswith('{') and ('type:' in line or 'text:' in line):
                try:
                    # ä¿®å¤JavaScriptå¯¹è±¡æ ¼å¼
                    # 1. æ›¿æ¢æ²¡æœ‰å¼•å·çš„é”®å
                    fixed_line = re.sub(r'(\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', line)
                    # 2. å¤„ç†çœç•¥å·
                    fixed_line = re.sub(r',\s*â€¦\s*}', ' }', fixed_line)
                    fixed_line = re.sub(r'â€¦\s*}', ' }', fixed_line)
                    # 3. å¤„ç†ç¼ºå°‘å€¼çš„é”®
                    fixed_line = re.sub(r',\s*"[^"]*":\s*,', ',', fixed_line)
                    fixed_line = re.sub(r',\s*"[^"]*":\s*}', ' }', fixed_line)
                    
                    # å°è¯•è§£æä¿®å¤åçš„JSON
                    obj = json.loads(fixed_line)
                    
                    # éªŒè¯å¿…éœ€å­—æ®µ
                    if 'text' in obj and obj['text'].strip():
                        # ç¡®ä¿æœ‰typeå­—æ®µ
                        if 'type' not in obj:
                            obj['type'] = 'text'
                        lines.append(obj)
                        
                except Exception as parse_error:
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•çš„æ–‡æœ¬æå–
                    text_match = re.search(r'"text":\s*"([^"]*)"', line)
                    if not text_match:
                        text_match = re.search(r'text:\s*"([^"]*)"', line)
                    
                    if text_match:
                        text = text_match.group(1)
                        if text.strip():
                            lines.append({"type": "text", "text": text})
                    else:
                        print(f"    è·³è¿‡æ— æ³•è§£æçš„è¡Œ {line_num}: {line[:50]}...")
                    continue
        
        if lines:
            print(f"é€è¡Œè§£ææˆåŠŸï¼Œæå– {len(lines)} æ¡è®°å½•")
        
        return lines
    

    
    async def convert_single_file(self, input_file: str, output_dir: str, 
                                temp_dir: Optional[str] = None, 
                                mode: str = "auto") -> str:
        """è½¬æ¢å•ä¸ªæ–‡ä»¶ï¼ˆPDFæˆ–JSONï¼‰"""
        input_type = self.detect_input_type(input_file)
        print(f"å¼€å§‹è½¬æ¢æ–‡ä»¶: {input_file}")
        print(f"æ£€æµ‹åˆ°è¾“å…¥ç±»å‹: {input_type}")
        
        self.validate_paths(input_file, output_dir)
        
        try:
            if input_type == "pdf_file":
                # PDFæ–‡ä»¶å¤„ç†æµç¨‹
                if temp_dir is None:
                    temp_dir = os.path.join(output_dir, "temp_json")
                
                # ç¬¬ä¸€æ­¥ï¼šPDFè½¬JSON
                json_files = self.convert_single_pdf_to_json(input_file, temp_dir, mode)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶é€‰é¡¹
                cleanup_temp = True
                
            elif input_type == "json_file":
                # JSONæ–‡ä»¶ç›´æ¥å¤„ç†
                json_files = self.collect_json_files(input_file)
                cleanup_temp = False
                
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {input_type}")
            
            # ç¬¬äºŒæ­¥ï¼šJSONè½¬é¢˜ç›®
            file_stem = Path(input_file).stem
            output_file = os.path.join(output_dir, f"{file_stem}_questions.json")
            
            questions = await self.convert_json_to_questions(json_files, output_file)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä»…PDFè½¬æ¢éœ€è¦ï¼‰
            if cleanup_temp and temp_dir:
                cleanup = input("æ˜¯å¦åˆ é™¤ä¸´æ—¶JSONæ–‡ä»¶? (y/N): ").lower().strip()
                if cleanup in ['y', 'yes']:
                    if os.path.exists(temp_dir):
                        shutil.rmtree(temp_dir, ignore_errors=True)
                        print("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            
            return output_file
            
        except Exception as e:
            print(f"è½¬æ¢å¤±è´¥: {e}")
            raise
    
    async def convert_folder(self, input_folder: str, output_dir: str,
                           mode: str = "auto") -> List[str]:
        """æ‰¹é‡è½¬æ¢æ–‡ä»¶å¤¹ï¼ˆPDFæˆ–JSONï¼‰"""
        input_type = self.detect_input_type(input_folder)
        print(f"å¼€å§‹æ‰¹é‡è½¬æ¢æ–‡ä»¶å¤¹: {input_folder}")
        print(f"æ£€æµ‹åˆ°è¾“å…¥ç±»å‹: {input_type}")
        
        self.validate_paths(input_folder, output_dir)
        
        try:
            if input_type == "pdf_folder":
                # PDFæ–‡ä»¶å¤¹å¤„ç†æµç¨‹
                temp_dir = os.path.join(output_dir, "temp_json")
                
                # ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡PDFè½¬JSON
                json_files = self.convert_pdf_folder_to_json(input_folder, temp_dir, mode)
                
                # ç¬¬äºŒæ­¥ï¼šJSONè½¬é¢˜ç›®ï¼ˆæŒ‰PDFåˆ†ç»„å¤„ç†ï¼‰
                pdf_files = []
                for root, dirs, files in os.walk(input_folder):
                    for file in files:
                        if file.lower().endswith('.pdf'):
                            pdf_files.append(os.path.join(root, file))
                
                output_files = []
                for pdf_file in pdf_files:
                    # æ‰¾åˆ°å¯¹åº”çš„JSONæ–‡ä»¶
                    pdf_name = Path(pdf_file).stem
                    related_json_files = [f for f in json_files if pdf_name in f]
                    
                    if related_json_files:
                        output_file = os.path.join(
                            output_dir, 
                            f"{pdf_name}_questions.json"
                        )
                        
                        await self.convert_json_to_questions(related_json_files, output_file)
                        output_files.append(output_file)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                cleanup = input("æ˜¯å¦åˆ é™¤ä¸´æ—¶JSONæ–‡ä»¶? (y/N): ").lower().strip()
                if cleanup in ['y', 'yes']:
                    if os.path.exists(temp_dir):
                        shutil.rmtree(temp_dir, ignore_errors=True)
                        print("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
                
            elif input_type == "json_folder":
                # JSONæ–‡ä»¶å¤¹ç›´æ¥å¤„ç†
                json_files = self.collect_json_files(input_folder)
                
                # å¯ä»¥é€‰æ‹©åˆå¹¶å¤„ç†æˆ–åˆ†åˆ«å¤„ç†
                process_type = input("æ‰¹é‡JSONå¤„ç†æ–¹å¼ - [1] åˆå¹¶ä¸ºå•ä¸ªè¾“å‡º [2] åˆ†åˆ«å¤„ç† (é»˜è®¤:1): ").strip()
                
                if process_type == "2":
                    # åˆ†åˆ«å¤„ç†æ¯ä¸ªJSONæ–‡ä»¶
                    output_files = []
                    for json_file in json_files:
                        file_name = Path(json_file).stem
                        output_file = os.path.join(output_dir, f"{file_name}_questions.json")
                        await self.convert_json_to_questions([json_file], output_file)
                        output_files.append(output_file)
                else:
                    # åˆå¹¶å¤„ç†
                    output_file = os.path.join(output_dir, "merged_questions.json")
                    await self.convert_json_to_questions(json_files, output_file)
                    output_files = [output_file]
            
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {input_type}")
            
            return output_files
            
        except Exception as e:
            print(f"æ‰¹é‡è½¬æ¢å¤±è´¥: {e}")
            raise

    # ä¿æŒå‘åå…¼å®¹çš„æ–¹æ³•å
    async def convert_single_pdf(self, pdf_file: str, output_dir: str, 
                               temp_dir: Optional[str] = None, 
                               mode: str = "auto") -> str:
        """è½¬æ¢å•ä¸ªPDFæ–‡ä»¶ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        return await self.convert_single_file(pdf_file, output_dir, temp_dir, mode)
    
    async def convert_pdf_folder(self, pdf_folder: str, output_dir: str,
                               mode: str = "auto") -> List[str]:
        """æ‰¹é‡è½¬æ¢PDFæ–‡ä»¶å¤¹ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        return await self.convert_folder(pdf_folder, output_dir, mode)

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="PDF/JSONè½¬é¢˜ç›®è½¬æ¢å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # è½¬æ¢å•ä¸ªPDFæ–‡ä»¶
  python main.py -i example.pdf -o ./output
  
  # è½¬æ¢å•ä¸ªJSONæ–‡ä»¶
  python main.py -i example.json -o ./output
  
  # æ‰¹é‡è½¬æ¢PDFæ–‡ä»¶å¤¹
  python main.py -i ./pdf_folder -o ./output --batch
  
  # æ‰¹é‡è½¬æ¢JSONæ–‡ä»¶å¤¹
  python main.py -i ./json_folder -o ./output --batch
  
  # æŒ‡å®šè½¬æ¢æ¨¡å¼ï¼ˆä»…PDFè½¬æ¢ï¼‰
  python main.py -i example.pdf -o ./output --mode ocr
  
  # æŒ‡å®šAPIå¯†é’¥
  python main.py -i example.pdf -o ./output --api-key sk-xxxxx
        """
    )
    
    parser.add_argument(
        "-i", "--input", 
        required=True,
        help="è¾“å…¥PDF/JSONæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„"
    )
    
    parser.add_argument(
        "-o", "--output",
        required=True,
        help="è¾“å‡ºç›®å½•è·¯å¾„"
    )
    
    parser.add_argument(
        "--batch",
        action="store_true",
        help="æ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆå¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼‰"
    )
    
    parser.add_argument(
        "--mode",
        choices=["auto", "txt", "ocr"],
        default="auto",
        help="PDFè½¬æ¢æ¨¡å¼ (é»˜è®¤: autoï¼Œä»…å¯¹PDFæ–‡ä»¶æœ‰æ•ˆ)"
    )
    
    parser.add_argument(
        "--api-key",
        help="SiliconFlow APIå¯†é’¥ï¼ˆä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡SILICONFLOW_API_KEYè®¾ç½®ï¼‰"
    )
    
    parser.add_argument(
        "--temp-dir",
        help="ä¸´æ—¶JSONæ–‡ä»¶ç›®å½•ï¼ˆé»˜è®¤åœ¨è¾“å‡ºç›®å½•ä¸‹åˆ›å»ºtemp_jsonï¼‰"
    )
    
    return parser.parse_args()

async def main():
    """ä¸»å‡½æ•°"""
    try:
        args = parse_arguments()
        
        print("=" * 60)
        print("      PDF/JSONè½¬é¢˜ç›®è½¬æ¢å™¨")
        print("=" * 60)
        
        # åˆå§‹åŒ–è½¬æ¢å™¨
        converter = PDF2QuestionConverter(args.api_key)
        
        # æ£€æµ‹è¾“å…¥ç±»å‹
        input_type = converter.detect_input_type(args.input)
        print(f"æ£€æµ‹åˆ°è¾“å…¥ç±»å‹: {input_type}")
        
        # æ ¹æ®æ¨¡å¼æ‰§è¡Œè½¬æ¢
        if args.batch:
            if not os.path.isdir(args.input):
                print("é”™è¯¯: æ‰¹é‡æ¨¡å¼éœ€è¦è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„")
                sys.exit(1)
            
            output_files = await converter.convert_folder(
                args.input, 
                args.output, 
                args.mode
            )
            
            print(f"\nè½¬æ¢å®Œæˆ! ç”Ÿæˆäº† {len(output_files)} ä¸ªé¢˜ç›®æ–‡ä»¶:")
            for file in output_files:
                print(f"  - {file}")
        
        else:
            if not os.path.isfile(args.input):
                print("é”™è¯¯: å•æ–‡ä»¶æ¨¡å¼éœ€è¦è¾“å…¥æ–‡ä»¶è·¯å¾„")
                sys.exit(1)
            
            output_file = await converter.convert_single_file(
                args.input,
                args.output,
                args.temp_dir,
                args.mode
            )
            
            print(f"\nè½¬æ¢å®Œæˆ! é¢˜ç›®æ–‡ä»¶: {output_file}")
        
        print("\nè½¬æ¢æˆåŠŸå®Œæˆ! ğŸ‰")
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 7):
        print("é”™è¯¯: éœ€è¦Python 3.7æˆ–æ›´é«˜ç‰ˆæœ¬")
        sys.exit(1)
    
    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())


